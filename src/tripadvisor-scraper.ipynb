{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, ElementNotInteractableException, StaleElementReferenceException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotel_links(url):\n",
    "    \"\"\"\n",
    "    Scrape hotel links from the given URL and return them as a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "    - url (str): the URL to scrape hotel links from\n",
    "\n",
    "    Returns:\n",
    "    - list: a list of dictionaries containing hotel links\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the Chrome driver with specified options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    #driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options = options)\n",
    "    # Set the path to the WebDriver executable (e.g., chromedriver or geckodriver)\n",
    "    driver_path = 'chromedriver.exe'\n",
    "\n",
    "    # Create a WebDriver instance (for Chrome in this example)\n",
    "    driver = webdriver.Chrome(executable_path=driver_path)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    \n",
    "    # Load the webpage with the given URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Initialize an empty list to store the hotel links\n",
    "    urls = []\n",
    "\n",
    "    # give the DOM time to load (3 seconds)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Wait for the element to become clickable\n",
    "    #wait = WebDriverWait(driver, 10)\n",
    "    #element = wait.until(EC.element_to_be_clickable((By.XPATH, \".//button[@class='rmyCe _G B- z _S c Wc wSSLS pexOo sOtnj']\")))\n",
    "\n",
    "    # Click the element\n",
    "    #element.click()\n",
    "\n",
    "    # Click the \"see all\" button to reveal the entire hotels.\n",
    "    #driver.find_element(\"xpath\", \".//button[@class='rmyCe _G B- z _S c Wc wSSLS pexOo sOtnj']\").click()\n",
    "\n",
    "    # Collapse the date panel if it is present\n",
    "    try:\n",
    "        collapseDatePanel = driver.find_element(\"xpath\", \".//div[@class='KWdaU Za f e']\")\n",
    "    except:\n",
    "        collapseDatePanel = None\n",
    "\n",
    "    if collapseDatePanel is not None:\n",
    "        collapseDatePanel.click()\n",
    "\n",
    "    # Get the number of hotels in Marrakech (778)\n",
    "    numberOfHotels = 30\n",
    "\n",
    "    # Scrape hotel links until we have enough\n",
    "    while len(urls) < numberOfHotels:\n",
    "\n",
    "        # Wait for the DOM to load (3 seconds)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Find all hotels in the current page and store them all to a container\n",
    "        #container = driver.find_elements(\"xpath\", \".//div[@class='jsTLT K']\")\n",
    "        container = driver.find_elements(\"xpath\", \".//div[contains(@class, 'jsTLT K') or contains(@class, 'listing_title')]/a\")\n",
    "\n",
    "        # Parse each hotel in the container\n",
    "        for j in range(len(container)):\n",
    "\n",
    "            # Print progress information\n",
    "            print(\"Progress: {}\".format(\"\" + str(len(urls)) + \"/\" + str(numberOfHotels)))\n",
    "\n",
    "            # If we have enough hotel links, stop parsing\n",
    "            if len(urls) >= numberOfHotels:\n",
    "                break\n",
    "\n",
    "            # Get the hotel link and append it to the list of URLs\n",
    "            hotelLink = container[j].get_attribute(\"href\")\n",
    "\n",
    "            urls.append({\n",
    "                'Hotel_Link': hotelLink\n",
    "            })\n",
    "\n",
    "    # Quit the driver when all pages have been processed\n",
    "    driver.quit()\n",
    "    \n",
    "    # Return the list of hotel links\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotel_links_and_update_csv(url: str) -> None:\n",
    "    \"\"\"\n",
    "    Scrape hotel links from the given URL, remove duplicate links from an existing CSV file,\n",
    "    and append the new links to the CSV file.\n",
    "\n",
    "    Args:\n",
    "    - url (str): the URL to scrape hotel links from\n",
    "    example: https://www.tripadvisor.com/Hotels-g293734-oa30-Marrakech_Marrakech_Safi-Hotels.html\n",
    "\n",
    "    Returns:\n",
    "    - None: the function does not return anything, but it updates the CSV file with the new links\n",
    "    \"\"\"\n",
    "\n",
    "    # Scrape and save the new links to a DataFrame\n",
    "    links = scrape_hotel_links(url)\n",
    "    df = pd.DataFrame(links)\n",
    "\n",
    "    # Remove the hotel links from the existing CSV file\n",
    "    df1 = pd.read_csv('Data/hotels_links.csv')\n",
    "    df = df[~df['Hotel_Link'].isin(df1['Hotel_Link'])]\n",
    "\n",
    "    # Append the new DataFrame to the existing CSV file\n",
    "    df1 = df1.append(df, ignore_index=True)\n",
    "    df1.to_csv('Data/hotels_links.csv', index=False)\n",
    "\n",
    "    # Save the DataFrame to a separate CSV file\n",
    "    df.to_csv('Data/hotels_links_30.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotel_reviews(url):\n",
    "    \"\"\"\n",
    "    Scrapes the reviews of a hotel from TripAdvisor.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the TripAdvisor page of the hotel.\n",
    "\n",
    "    Returns:\n",
    "        reviews (list): A list of dictionaries, each containing the following keys:\n",
    "            - hotelName: The name of the hotel.\n",
    "            - reviewDate: The date of the review.\n",
    "            - reviewRating: The rating given by the reviewer.\n",
    "            - reviewTitle: The title of the review.\n",
    "            - reviewText: The text of the review.\n",
    "            - reviewerProfileLink: The link to the profile page of the reviewer.\n",
    "            - dateOfStay: The date of the stay.\n",
    "            - tripType: The type of trip.\n",
    "            - reviewerLocation: The location of the reviewer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up the Chrome driver with specified options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options = options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    \n",
    "    # Load the webpage with the given URL\n",
    "    driver.get(url)\n",
    "        \n",
    "    # Initialize an empty list to store the reviews\n",
    "    reviews = []\n",
    "\n",
    "    # give the DOM time to load (3 seconds)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Grab the hotel name\n",
    "    hotelName = driver.find_element(\"xpath\",\"//h1[@id='HEADING']\").text\n",
    "\n",
    "    # Grab the number of english reviews\n",
    "    numberOfReviewsStr = driver.find_element(\"xpath\",\".//label[@class='Qukvo Vm _S']/span[text()='English']/following-sibling::span[1]\").text\n",
    "    numberOfReviews = int(numberOfReviewsStr.strip('()').replace(',', ''))\n",
    "\n",
    "    # Scrape hotel reviews until we have enough\n",
    "    while len(reviews) < numberOfReviews:\n",
    "\n",
    "        # give the DOM time to load (3 seconds)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Wait for the element to become clickable\n",
    "        #wait = WebDriverWait(driver, 10)\n",
    "        #element = wait.until(EC.element_to_be_clickable((By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\")))\n",
    "\n",
    "        # Click the element\n",
    "        #element.click()\n",
    "\n",
    "        # Click the \"expand review\" link to reveal the entire review.\n",
    "        #driver.find_element(\"xpath\", \".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "        try:\n",
    "            driver.find_element(\"xpath\", \".//span[@class='Ignyf _S Z']\").click()\n",
    "        except ElementNotInteractableException:\n",
    "            element = driver.find_element(\"xpath\", \".//span[@class='Ignyf _S Z']\")\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "        # Find all reviews in the current page and store them all to a container\n",
    "        container = driver.find_elements(\"xpath\", \"//div[contains(@data-test-target, 'HR_CC_CARD')]\")\n",
    "\n",
    "        # Parse each review in the container\n",
    "        for j in range(len(container)):\n",
    "\n",
    "            # Print progress information\n",
    "            print(\"Progress: {}\".format(\"\" + str(len(reviews)) + \"/\" + str(numberOfReviews)))\n",
    "\n",
    "            # If we have enough hotel reviews, stop parsing\n",
    "            if len(reviews) >= numberOfReviews:\n",
    "                break\n",
    "\n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the review date\n",
    "                    reviewDate = container[j].find_element(\"xpath\", \".//div[@class='cRVSd']/span\").text\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    reviewDate = None\n",
    "                    break\n",
    "\n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the rating\n",
    "                    reviewRating = container[j].find_element(\"xpath\", \".//span[contains(@class, 'ui_bubble_rating bubble_')]\").get_attribute(\"class\").split(\"_\")[3]\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    reviewRating = None\n",
    "                    break\n",
    "\n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the title\n",
    "                    reviewTitle = container[j].find_element(\"xpath\",\".//div[contains(@data-test-target, 'review-title')]\").text\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    reviewTitle = None\n",
    "                    break\n",
    "\n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the review text, removing newlines and commas\n",
    "                    reviewText = container[j].find_element(\"xpath\", \".//q[@class='QewHA H4 _a']\").text.replace(\"\\n\", \"  \").replace(\",\", \"\")\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    reviewText = None\n",
    "                    break\n",
    "                \n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the reviewer profile link\n",
    "                    reviewerProfileLink = container[j].find_element(\"xpath\", \".//div[@class='cRVSd']/span/a\").get_attribute(\"href\")\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    reviewerProfileLink = None\n",
    "                    break\n",
    "                \n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the reviewer Date of stay\n",
    "                    dateOfStay = container[j].find_element(\"xpath\", \".//span[@class='teHYY _R Me S4 H3']\").text\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    dateOfStay = None\n",
    "                    break\n",
    "\n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the reviewer Trip type\n",
    "                    tripType = container[j].find_element(\"xpath\", \".//span[@class='TDKzw _R Me']\").text\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)              \n",
    "                except NoSuchElementException:\n",
    "                    tripType = None\n",
    "                    break\n",
    "\n",
    "            retry_count = 0\n",
    "            while retry_count < 3:\n",
    "                try:\n",
    "                    # Grab the reviewer location\n",
    "                    reviewerLocation = container[j].find_element(\"xpath\", \".//span[@class='default LXUOn small']\").text\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    retry_count += 1\n",
    "                    # If the element has become stale, wait and try again\n",
    "                    time.sleep(2)\n",
    "                except NoSuchElementException:\n",
    "                    # Handle the case where an element is not found  \n",
    "                    reviewerLocation = None\n",
    "                    break\n",
    "\n",
    "            reviews.append({'Hotel_Name':hotelName,\n",
    "                            'Review_Date':reviewDate,\n",
    "                            'Review_Rating':reviewRating,\n",
    "                            'Review_Title':reviewTitle,\n",
    "                            'Review_Text':reviewText,\n",
    "                            'Reviewer_Date_Of_Stay':dateOfStay,\n",
    "                            'Reviewer_Trip_Type':tripType,\n",
    "                            'Reviewer_Location':reviewerLocation,\n",
    "                            'Reviewer_Profile_Link':reviewerProfileLink})\n",
    "\n",
    "        try:\n",
    "            # When all the reviews in the container have been processed, move to the next page and repeat\n",
    "            next_page = driver.find_element(\"xpath\", './/a[contains(@class, \"ui_button nav next primary \")]').click()\n",
    "        except StaleElementReferenceException:\n",
    "            # If the element has become stale, wait and try again\n",
    "            time.sleep(2)\n",
    "            next_page = driver.find_element(\"xpath\", './/a[contains(@class, \"ui_button nav next primary \")]').click()\n",
    "        except NoSuchElementException:\n",
    "            print('next page failed')\n",
    "\n",
    "    # Quit the driver when all pages have been processed\n",
    "    driver.quit()\n",
    "    \n",
    "    # Return the list of hotel reviews\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hotel_reviews_and_save(n):\n",
    "    \"\"\"\n",
    "    Scrapes and saves hotel reviews for a given range of hotels.\n",
    "\n",
    "    Args:\n",
    "        n (int): The starting index in the list of hotel links to scrape from.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    hotel_links = pd.read_csv('Data/hotels_links_30.csv')\n",
    "\n",
    "    for index in range(n,len(hotel_links)):\n",
    "        url = hotel_links['Hotel_Link'][index]\n",
    "        # First scrape and save the reviews to a DataFrame\n",
    "        reviews = scrape_hotel_reviews(url)\n",
    "        df = pd.DataFrame(reviews)\n",
    "\n",
    "        start_index = url.find(\"Reviews-\") + len(\"Reviews-\")\n",
    "        end_index = url.find(\"-Marrakech_Marrakech_Safi\")\n",
    "\n",
    "        hotel_name = url[start_index:end_index]\n",
    "        # Save the DataFrame to the CSV file\n",
    "        df.to_csv('Data/Reviews/'+ hotel_name +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files():\n",
    "    \"\"\"\n",
    "    Merges all the CSV files in the 'Data/Reviews' folder into a single file named 'marrakech_hotels_reviews.csv'.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    file_list = glob.glob(\"Data/Reviews/*.csv\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_csv(file_name)\n",
    "        print(len(temp_df))\n",
    "        df = df.append(temp_df, ignore_index=True)\n",
    "\n",
    "    df.to_csv('Data/marrakech_hotels_reviews.csv', index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
